{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project 6 - Real-Time Anomaly Segmentation for Road Scenes\n"
      ],
      "metadata": {
        "id": "hjMRzmj5jPAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone of git repository"
      ],
      "metadata": {
        "id": "7uSxHpHQnTQi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMYUJsKXqSlg"
      },
      "outputs": [],
      "source": [
        "# Installa Git se non è già disponibile (opzionale)\n",
        "!apt-get install git\n",
        "\n",
        "# Clona il repository (sostituisci il link con quello del tuo repository GitHub)\n",
        "!rm -rf /content/AnomalySegmentation_CourseProjectBaseCode\n",
        "!git clone https://github.com/FrancescoPassiatore/AnomalySegmentation_CourseProjectBaseCode.git\n",
        "\n",
        "# Installa le dipendenze\n",
        "\n",
        "!pip install ood-metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch needed datasets from Google Drive"
      ],
      "metadata": {
        "id": "J-aDWrsBnM77"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYjy4LWCjrrp",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download of cityscapes dataset + generating labels"
      ],
      "metadata": {
        "id": "SBZCL-RRmutE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install cityscapesscripts[gui] && csDownload\n",
        "!mkdir /content/cityscapes\n",
        "!csDownload gtFine_trainvaltest.zip -d /content/cityscapes\n",
        "!csDownload leftImg8bit_trainvaltest.zip -d /content/cityscapes\n",
        "!unzip /content/cityscapes/gtFine_trainvaltest.zip -d /content/cityscapes\n",
        "!unzip /content/cityscapes/leftImg8bit_trainvaltest.zip -d /content/cityscapes\n",
        "!CITYSCAPES_DATASET='/content/cityscapes/' csCreateTrainIdLabelImgs"
      ],
      "metadata": {
        "id": "XU1bu62EmVxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2a - Evaluation (MSP, MaxLogit, MaxEntropy)"
      ],
      "metadata": {
        "id": "V459v7qAj3Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os"
      ],
      "metadata": {
        "id": "TZ6_9R2ekTT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNJE4h4_pdrs"
      },
      "outputs": [],
      "source": [
        "for dataset in ['RoadAnomaly21','RoadObsticle21','fs_static','FS_LostFound_full','RoadAnomaly']:\n",
        "  for method in ['MSP','MaxLogit','MaxEntropy']:\n",
        "\n",
        "    format_file = os.listdir(f'/content/drive/MyDrive/Validation_Dataset/{dataset}/images')[0].split(\".\")[1]\n",
        "    input = f'/content/drive/MyDrive/Validation_Dataset/{dataset}/images/\\*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset} - method : {method }\")\n",
        "    dir = f'/content/AnomalySegmentation_CourseProjectBaseCode/trained_models/'\n",
        "\n",
        "    !python -W ignore /content/AnomalySegmentation_CourseProjectBaseCode/eval/evalAnomaly.py --input {input} --method {method}  --loadDir {dir}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation of mIoU on Cityscapes dataset\n",
        "!python /content/AnomalySegmentation_CourseProjectBaseCode/eval/eval_iou.py --datadir /content/cityscapes/ --subset val --loadDir /content/AnomalySegmentation_CourseProjectBaseCode/trained_models/ --loadWeights erfnet_pretrained.pth"
      ],
      "metadata": {
        "id": "EQIE06PXnBap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2b - Evaluation temperature scaling"
      ],
      "metadata": {
        "id": "RaATblJMl9GT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in ['RoadAnomaly21','RoadObsticle21','fs_static','FS_LostFound_full','RoadAnomaly']:\n",
        "  for temperature in [0.1,0.25,0.5,0.75,1.1,1.5,2.0,2.5,3.0]:\n",
        "\n",
        "    #Method is default MSP\n",
        "    format_file = os.listdir(f'/content/drive/MyDrive/Validation_Dataset/{dataset}/images')[0].split(\".\")[1]\n",
        "    input = f'/content/drive/MyDrive/Validation_Dataset/{dataset}/images/\\*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset} - temperature : {temperature}\")\n",
        "    dir = f'/content/AnomalySegmentation_CourseProjectBaseCode/trained_models/'\n",
        "\n",
        "    !python -W ignore /content/AnomalySegmentation_CourseProjectBaseCode/eval/evalAnomaly.py --input {input} --temperature {temperature}  --loadDir {dir}"
      ],
      "metadata": {
        "id": "cqtfZxSglGqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation for 3 - Training models"
      ],
      "metadata": {
        "id": "4gESJRWJmW1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install visdom"
      ],
      "metadata": {
        "id": "59kAJti_p1hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We modified every time the main function in /train. For better understanding in the GitHub repo everything is ordered in folders."
      ],
      "metadata": {
        "id": "unJGMo1ooaGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training for Bisenet starting from a pretrained model found here : https://github.com/CoinCheung/BiSeNet"
      ],
      "metadata": {
        "id": "y65-pjf4o1oV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'bisenetv1'\n",
        "dir = f'/content/AnomalySegmentation_CourseProjectBaseCode/trained_models/bisenetv1_pretrained.pth'\n",
        "!cd \"/content/AnomalySegmentation_CourseProjectBaseCode/train/\" && python -W ignore /content/AnomalySegmentation_CourseProjectBaseCode/train/main.py --state {dir} --datadir '/content/cityscapes/' --model {model} --savedir '/content/training_output_bisenet/' --num-epochs=20 --epochs-save=1"
      ],
      "metadata": {
        "id": "lRlag9dnnnQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training for ENet starting from a pretraned model found here : https://github.com/davidtvs/PyTorch-ENet"
      ],
      "metadata": {
        "id": "M3HWOpCzpETr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'enet'\n",
        "dir = f'/content/AnomalySegmentation_CourseProjectBaseCode/trained_models/ENet'\n",
        "!cd \"/content/AnomalySegmentation_CourseProjectBaseCode/train/\" && python -W ignore /content/AnomalySegmentation_CourseProjectBaseCode/train/main.py --state {dir} --datadir '/content/cityscapes/' --model {model} --savedir '/content/training_output_enet/' --num-epochs=20 --epochs-save=1"
      ],
      "metadata": {
        "id": "xvzJdzGhpS2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training for ERFNet startng from initial repo"
      ],
      "metadata": {
        "id": "6AH7DhQxpg43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'erfnet'\n",
        "dir = f'/content/AnomalySegmentation_CourseProjectBaseCode/trained_models/erfnet_pretrained.pth'\n",
        "!cd \"/content/AnomalySegmentation_CourseProjectBaseCode/train/\" && python -W ignore /content/AnomalySegmentation_CourseProjectBaseCode/train/main.py --state {dir} --datadir '/content/cityscapes/' --model {model} --savedir '/content/training_output_erfnet/' --num-epochs=20 --epochs-save=1"
      ],
      "metadata": {
        "id": "oqRzCpB9pmSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Void classification"
      ],
      "metadata": {
        "id": "Aao8vNHLmOjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Three different evaluations for the 3 models. We load the weights from the respective model_best.pth generated from each training."
      ],
      "metadata": {
        "id": "My2D1IOyqm2X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "D9Lrqc4vdRCe"
      },
      "outputs": [],
      "source": [
        "for dataset in ['RoadAnomaly21','RoadObsticle21','fs_static','FS_LostFound_full','RoadAnomaly']:\n",
        "  for method in ['Void']:\n",
        "\n",
        "    format_file = os.listdir(f'/content/drive/MyDrive/Validation_Dataset/{dataset}/images')[0].split(\".\")[1]\n",
        "    input = f'/content/drive/MyDrive/Validation_Dataset/{dataset}/images/\\*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset} - method : {method}\")\n",
        "    dir = f'/content/AnomalySegmentation_CourseProjectBaseCode/trained_models/'\n",
        "    !python -W ignore /content/AnomalySegmentation_CourseProjectBaseCode/eval/evalAnomaly.py --input {input} --loadModel 'enet.py' --method {method} --loadDir {dir} --loadWeights 'model_best.pth'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in ['RoadAnomaly21','RoadObsticle21','fs_static','FS_LostFound_full','RoadAnomaly']:\n",
        "  for method in ['Void']:\n",
        "\n",
        "    format_file = os.listdir(f'/content/drive/MyDrive/Validation_Dataset/{dataset}/images')[0].split(\".\")[1]\n",
        "    input = f'/content/drive/MyDrive/Validation_Dataset/{dataset}/images/\\*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset} - method : {method}\")\n",
        "    dir = f'/content/AnomalySegmentation_CourseProjectBaseCode/trained_models/'\n",
        "    !python -W ignore /content/AnomalySegmentation_CourseProjectBaseCode/eval/evalAnomaly.py --input {input} --loadModel 'bisenetv1.py' --method {method} --loadDir {dir} --loadWeights 'model_best.pth'"
      ],
      "metadata": {
        "id": "9MveKJ2kqZoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in ['RoadAnomaly21','RoadObsticle21','fs_static','FS_LostFound_full','RoadAnomaly']:\n",
        "  for method in ['Void']:\n",
        "\n",
        "    format_file = os.listdir(f'/content/drive/MyDrive/Validation_Dataset/{dataset}/images')[0].split(\".\")[1]\n",
        "    input = f'/content/drive/MyDrive/Validation_Dataset/{dataset}/images/\\*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset} - method : {method}\")\n",
        "    dir = f'/content/AnomalySegmentation_CourseProjectBaseCode/trained_models/'\n",
        "    !python -W ignore /content/AnomalySegmentation_CourseProjectBaseCode/eval/evalAnomaly.py --input {input} --loadModel 'erfnet.py' --method {method} --loadDir {dir} --loadWeights 'model_best.pth'"
      ],
      "metadata": {
        "id": "D6B0C4YCqae5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWDhpZt9270v"
      },
      "source": [
        "Evaluation of mIoU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/AnomalySegmentation_CourseProjectBaseCode/eval/eval_iou.py --datadir /content/cityscapes/ --loadModel erfnet.py --subset val --loadDir /content/AnomalySegmentation_CourseProjectBaseCode/trained_models/ --loadWeights model_best.pth"
      ],
      "metadata": {
        "id": "qK_kdO7UAfv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/AnomalySegmentation_CourseProjectBaseCode/eval/eval_iou.py --datadir /content/cityscapes/ --loadModel bisenetv1.py --subset val --loadDir /content/AnomalySegmentation_CourseProjectBaseCode/trained_models/ --loadWeights model_best.pth"
      ],
      "metadata": {
        "id": "kRsgcy4orLuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/AnomalySegmentation_CourseProjectBaseCode/eval/eval_iou.py --datadir /content/cityscapes/ --loadModel enet.py --subset val --loadDir /content/AnomalySegmentation_CourseProjectBaseCode/trained_models/ --loadWeights model_best.pth"
      ],
      "metadata": {
        "id": "e3_oJ5yarMLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 -  Effect of Training Loss function"
      ],
      "metadata": {
        "id": "LJEAyB_1rgVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As for the training of models we modified every time the main.py. The correct implementation is in the repo under the respective folder."
      ],
      "metadata": {
        "id": "K2gPgnTGsx5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training erfnet with IsoMaxPlus (CE alreasy included in secondpart of formula)"
      ],
      "metadata": {
        "id": "omHXkkgQsJs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'erfnet'\n",
        "dir = f'/content/AnomalySegmentation_CourseProjectBaseCode/trained_models/erfnet_pretrained.pth'\n",
        "!cd \"/content/AnomalySegmentation_CourseProjectBaseCode/train/\" && python -W ignore /content/AnomalySegmentation_CourseProjectBaseCode/train/main.py  --state {dir} --datadir '/content/cityscapes/' --model {model} --savedir '/content/training_output_erfnet_w_isomax_plus/' --num-epochs=20 --epochs-save=1"
      ],
      "metadata": {
        "id": "RdSzR5ZssCNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training erfnet with IsoMaxPlus and FocalLoss"
      ],
      "metadata": {
        "id": "Fj4Wi1HwsnWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'erfnet'\n",
        "dir = f'/content/AnomalySegmentation_CourseProjectBaseCode/trained_models/erfnet_pretrained.pth'\n",
        "!cd \"/content/AnomalySegmentation_CourseProjectBaseCode/train/\" && python -W ignore /content/AnomalySegmentation_CourseProjectBaseCode/train/main.py  --state {dir} --datadir '/content/cityscapes/' --model {model} --savedir '/content/training_output_erfnet_w_isomax_plus_focal/' --num-epochs=20 --epochs-save=1"
      ],
      "metadata": {
        "id": "69KXVB_otE0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation made for both IsoMaxPlus with and without FocalLoss . In model_best.pth the trained models."
      ],
      "metadata": {
        "id": "EZHdThbDte9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for dataset in ['RoadAnomaly21','RoadObsticle21','fs_static','FS_LostFound_full','RoadAnomaly']:\n",
        "  for method in ['MSP','MaxLogit','MaxEntropy']:\n",
        "\n",
        "\n",
        "    format_file = os.listdir(f'/content/drive/MyDrive/Validation_Dataset/{dataset}/images')[0].split(\".\")[1]\n",
        "    input = f'/content/drive/MyDrive/Validation_Dataset/{dataset}/images/\\*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset} - method : {method}\")\n",
        "    dir = f'/content/AnomalySegmentation_CourseProjectBaseCode/trained_models/'\n",
        "    !python -W ignore /content/AnomalySegmentation_CourseProjectBaseCode/eval/evalAnomaly.py --input {input} --method {method} --loadWeights model_best.pth --loadDir {dir}\n"
      ],
      "metadata": {
        "id": "uJERFsdttN49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation of mIoU for both IsoMaxPLus with and without FocalLoss."
      ],
      "metadata": {
        "id": "E5kTnHWWRFB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/AnomalySegmentation_CourseProjectBaseCode/eval/eval_iou.py --datadir /content/cityscapes/ --loadModel ernet.py --subset val --loadDir /content/AnomalySegmentation_CourseProjectBaseCode/trained_models/ --loadWeights model_best.pth"
      ],
      "metadata": {
        "id": "UA96tMNEQ-bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training erfnet with LogitNorm"
      ],
      "metadata": {
        "id": "kFJIo2gLtrh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install visdom\n",
        "\n",
        "model = 'erfnet'\n",
        "dir = f'/content/AnomalySegmentation_CourseProjectBaseCode/trained_models/erfnet_pretrained.pth'\n",
        "!cd \"/content/AnomalySegmentation_CourseProjectBaseCode/train/\" && python -W ignore /content/AnomalySegmentation_CourseProjectBaseCode/train/train_efnet_logit_norm/erfnet_logit_norm.py --state {dir} --datadir '/content/cityscapes/' --model {model} --savedir '/content/logitNorm_CrossEntropy/' --num-epochs=20 --epochs-save=1"
      ],
      "metadata": {
        "id": "NcTb5AdOt0Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training erfnet with LogitNorm and FocalLoss"
      ],
      "metadata": {
        "id": "ll8SFuhBtrOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install visdom\n",
        "\n",
        "model = 'erfnet'\n",
        "dir = f'/content/AnomalySegmentation_CourseProjectBaseCode/trained_models/erfnet_pretrained.pth'\n",
        "!cd \"/content/AnomalySegmentation_CourseProjectBaseCode/train/\" && python -W ignore /content/AnomalySegmentation_CourseProjectBaseCode/train/train_erfnet_logit_norm_focal/erfnet_focal_logit.py --state {dir} --datadir '/content/cityscapes/' --model {model} --savedir '/content/training_output_logitnorm/' --num-epochs=20 --epochs-save=1"
      ],
      "metadata": {
        "id": "ve9fJVvGt0kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation made for both LogitNorm with and without FocalLoss . In model_best.pth the trained models."
      ],
      "metadata": {
        "id": "7g3CclHIGhQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in ['RoadAnomaly21','RoadObsticle21','fs_static','FS_LostFound_full','RoadAnomaly']:\n",
        "  for method in ['MSP','MaxLogit','MaxEntropy']:\n",
        "\n",
        "\n",
        "    format_file = os.listdir(f'/content/drive/MyDrive/Validation_Dataset/{dataset}/images')[0].split(\".\")[1]\n",
        "    input = f'/content/drive/MyDrive/Validation_Dataset/{dataset}/images/\\*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset} - method : {method}\")\n",
        "    dir = f'/content/AnomalySegmentation_CourseProjectBaseCode/trained_models/'\n",
        "    !python -W ignore /content/AnomalySegmentation_CourseProjectBaseCode/eval/evalAnomaly.py --input {input} --method {method} --loadWeights model_best.pth --loadDir {dir}"
      ],
      "metadata": {
        "id": "l5FgfUKnGg8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation of mIoU for both LogitNormalization with and without FocalLoss."
      ],
      "metadata": {
        "id": "Xiel1K7HRSYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/AnomalySegmentation_CourseProjectBaseCode/eval/eval_iou.py --datadir /content/cityscapes/ --loadModel ernet.py --subset val --loadDir /content/AnomalySegmentation_CourseProjectBaseCode/trained_models/ --loadWeights model_best.pth"
      ],
      "metadata": {
        "id": "B_XW5FG0RP87"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}